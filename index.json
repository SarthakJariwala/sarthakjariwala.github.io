[{"content":"Delete a git tag git tag -d v1.0.1 Here, v1.0.1 is the tag we want to delete.\nRemove it from remote/GitHub git push origin :v1.0.1 Note the \u0026ldquo;:\u0026rdquo; before the tag you want to remove from remote.\n","permalink":"https://sarthakjariwala.github.io/code/git/deleting_tag/","summary":"Delete a git tag git tag -d v1.0.1 Here, v1.0.1 is the tag we want to delete.\nRemove it from remote/GitHub git push origin :v1.0.1 Note the \u0026ldquo;:\u0026rdquo; before the tag you want to remove from remote.","title":"Delete Git Tag"},{"content":"Create a new git tag git tag v1.0.1 View tags git tag --list Push new tag to GitHub git push --tags ","permalink":"https://sarthakjariwala.github.io/code/git/creating_tag/","summary":"Create a new git tag git tag v1.0.1 View tags git tag --list Push new tag to GitHub git push --tags ","title":"Create and Push New Git Tag"},{"content":"Create a new conda environment # create a new conda environment called ml-ninja conda create --name ml-ninja Create a new environment with packages # create a new environment with python=3.9 and numpy installed conda create --name ml-ninja python=3.9 numpy Verify environment creation conda env list # conda environments: # # base * # ml-ninja ","permalink":"https://sarthakjariwala.github.io/code/conda/create-new-environment/","summary":"Create a new conda environment # create a new conda environment called ml-ninja conda create --name ml-ninja Create a new environment with packages # create a new environment with python=3.9 and numpy installed conda create --name ml-ninja python=3.9 numpy Verify environment creation conda env list # conda environments: # # base * # ml-ninja ","title":"Create New Environment"},{"content":"Preliminaries import numpy as np # create an array a = np.array([1, 2, -1]) Pad array on both sides with constant values Add two 3\u0026rsquo;s to the left of the array and four -7\u0026rsquo;s to the right of the array.\nnp.pad(a, (2, 4), \u0026#34;constant\u0026#34;, constant_values=(3, -7)) # array([ 3, 3, 1, 2, -1, -7, -7, -7, -7]) Pad array on only one side But, what if you only want to pad the right side or left side?\nPad only left side # Pad only left side np.pad(a, (2, 0), \u0026#34;constant\u0026#34;, constant_values=(3)) # array([ 3, 3, 1, 2, -1]) Pad only right side # Pad only right side\u0026#34;\u0026#34;\u0026#34; np.pad(a, (0, 4), \u0026#34;constant\u0026#34;, constant_values=(-7)) # array([ 1, 2, -1, -7, -7, -7, -7]) ","permalink":"https://sarthakjariwala.github.io/code/numpy/pad-an-array/","summary":"Preliminaries import numpy as np # create an array a = np.array([1, 2, -1]) Pad array on both sides with constant values Add two 3\u0026rsquo;s to the left of the array and four -7\u0026rsquo;s to the right of the array.\nnp.pad(a, (2, 4), \u0026#34;constant\u0026#34;, constant_values=(3, -7)) # array([ 3, 3, 1, 2, -1, -7, -7, -7, -7]) Pad array on only one side But, what if you only want to pad the right side or left side?","title":"Pad Numpy Array"},{"content":"Preliminary # load library import numpy as np Create a multi-dimensional array m = np.zeros(shape=(100, 32, 50)) Swap dimensions # swap axis 1 and 2 with each other in array `m` m_swapped = np.swapaxes(m, 1, 2) # view the shape m_swapped.shape (100, 50, 32) ","permalink":"https://sarthakjariwala.github.io/code/numpy/swap-axes-in-an-array/","summary":"Preliminary # load library import numpy as np Create a multi-dimensional array m = np.zeros(shape=(100, 32, 50)) Swap dimensions # swap axis 1 and 2 with each other in array `m` m_swapped = np.swapaxes(m, 1, 2) # view the shape m_swapped.shape (100, 50, 32) ","title":"Swap Axes in Array"},{"content":"Preliminaries If you have multiple services listed in your docker-compose file as shown below:\n# example docker-compose.yml version: \u0026#34;3.7\u0026#34; services: test: image: ezconda-test build: context: ./ dockerfile: Dockerfile container_name: ezconda-test dev: image: ezconda-dev build: context: ./ dockerfile: Dockerfile.dev container_name: ezconda-dev Build and Run a Specific Service To only build and run the dev service:\ndocker-compose build dev \u0026amp;\u0026amp; docker-compose run dev bash Here, bash is the command that we want to run in the container.\n","permalink":"https://sarthakjariwala.github.io/code/docker/build-run-single-service/","summary":"Preliminaries If you have multiple services listed in your docker-compose file as shown below:\n# example docker-compose.yml version: \u0026#34;3.7\u0026#34; services: test: image: ezconda-test build: context: ./ dockerfile: Dockerfile container_name: ezconda-test dev: image: ezconda-dev build: context: ./ dockerfile: Dockerfile.dev container_name: ezconda-dev Build and Run a Specific Service To only build and run the dev service:\ndocker-compose build dev \u0026amp;\u0026amp; docker-compose run dev bash Here, bash is the command that we want to run in the container.","title":"Build \u0026 Run a Single Service from docker-compose"},{"content":"I came across codespell via Simon Willison\u0026rsquo;s tweet.\nCodespell is a python library that provides a cli to check and fix common misspellings in text files.\nJust running it against the content of this website, I discovered a few misspellings.\ncodespell content The changes suggested by codespell can be implemented with a -w flag.\n","permalink":"https://sarthakjariwala.github.io/til/codespell/","summary":"I came across codespell via Simon Willison\u0026rsquo;s tweet.\nCodespell is a python library that provides a cli to check and fix common misspellings in text files.\nJust running it against the content of this website, I discovered a few misspellings.\ncodespell content The changes suggested by codespell can be implemented with a -w flag.","title":"Codespell - check spelling"},{"content":"Preliminaries from prefect.executors import LocalDaskExecutor, DaskExecutor from prefect import task, Flow from typing import Iterable Create a Prefect Task # create sample prefect task to run in a flow @task def add(list_of_int: Iterable[int]): return list_of_int[0] + list_of_int[1] Create a Prefect Flow # list of integers to add list_of_ints = [[1, 2], [-3, 5], [4, 5], [9, 0], [3, -8]] # create prefect Flow to run with Dask Executors with Flow(\u0026#34;sample-flow\u0026#34;) as flow: result = add.map(list_of_ints) With LocalDaskExecutor if __name__ == \u0026#34;__main__\u0026#34;: flow.run(executor=LocalDaskExecutor(scheduler=\u0026#34;processes\u0026#34;, num_workers=4)) With DaskExecutor if __name__ == \u0026#34;__main__\u0026#34;: flow.run(executor=DaskExecutor(cluster_kwargs={\u0026#34;n_workers\u0026#34;: 4})) Note: LocalDaskExecutor uses num_workers and DaskExecutor uses n_workers to specify the number of workers.\n","permalink":"https://sarthakjariwala.github.io/code/prefect/local-dask-executor/","summary":"Preliminaries from prefect.executors import LocalDaskExecutor, DaskExecutor from prefect import task, Flow from typing import Iterable Create a Prefect Task # create sample prefect task to run in a flow @task def add(list_of_int: Iterable[int]): return list_of_int[0] + list_of_int[1] Create a Prefect Flow # list of integers to add list_of_ints = [[1, 2], [-3, 5], [4, 5], [9, 0], [3, -8]] # create prefect Flow to run with Dask Executors with Flow(\u0026#34;sample-flow\u0026#34;) as flow: result = add.","title":"Dask Executor in Prefect"},{"content":" A comparative look at solar resource availability\nIs solar energy a viable resource for a city like Seattle? My friend recently asked me this question. I believe it\u0026rsquo;s a fair question to ask. Seattle isn\u0026rsquo;t known for its abundance of sunshine. As I write this post, it is a gloomy, cloudy and rainy day in Seattle. For those familiar with Seattle weather, this is not a surprise - fall and winter months are often cloudy and rainy.\nIn this post, we will answer this question by taking a look at the available solar resource for Seattle. We will also compare it against other cities - Boston, Austin and Berlin.\nNote - this post is not a discussion on the differences in the local policies but only the resource availability.\nWhere do we get solar resource data? National Renewable Energy Lab (NREL) provides access to the National Solar Radiation Database (NSRDB). NSRDB is collection of hourly and half-hourly values of meteorological data and solar radiation measurements.\nWe will download the data and perform the analysis using Python (You can also use the web interface to download the data, if you prefer).\nTo download the data programmatically, we will need a NREL Developer API key - it is free and the signup only requires your name and email (where you will receive the API key).\nInstallation We will use a Python API that I have created, nrel-dev-api, to programmatically access data and analysis services from NREL. It currently covers all of the solar API endpoints that NREL provides, with future support for other services such as wind, electricity, etc.\npip install --upgrade nrel-dev-api Set your API key from nrel_dev_api import set_nrel_api_key set_nrel_api_key(\u0026#34;YOUR_NREL_API_KEY\u0026#34;) Download NSRDB data To download the data, we need the latitude and longitude for our city of interest as well as the year and time interval of our data. Seattle\u0026rsquo;s latitude and longitude are 47.61 and -122.35, respectively.\nFirst, we will check to see if there are any data available for the specified year, interval and location.\nfrom nrel_dev_api.solar import (download_nsrdb_data, get_nsrdb_download_links) seattle_links = get_nsrdb_download_links(year=2016, interval=60, lat=47.61, lon=-122.35) seattle_links [\u0026#39;https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?names=2016\u0026amp;wkt=POINT%28-122.35+47.61%29\u0026amp;interval=60\u0026amp;api_key=yourapikey\u0026amp;email=youremail\u0026#39;] The above get_nsrdb_download_links returns a list of available links for the location and year of interest. Once we have the links, we can pass them to download_nsrdb_data to download the data.\nseattle_hourly_df = download_nsrdb_data(seattle_links[0], email=\u0026#34;YOUR_EMAIL\u0026#34;) The download_nsrdb_data function returns a pandas dataframe containing hourly irradiance, temperature, humidity, pressure, etc. The specific value of interest to us here is the column named \u0026ldquo;GHI\u0026rdquo; which stands for \u0026lsquo;Global Horizontal Irradiance\u0026rsquo;.\nGlobal horizontal irradiance is the amount of irradiance falling on a surface that is horizontal to the surface of the earth. This value is of particular interest for solar installations.\nWe will first resample the \u0026ldquo;GHI\u0026rdquo; data monthly and then sum it up to create monthly global horizontal irrandiance data.\nseattle_ghi_monthly_sum = 1e-3 * seattle_hourly_df[\u0026#34;GHI\u0026#34;].resample(\u0026#34;M\u0026#34;).sum() Note - the \u0026ldquo;GHI\u0026rdquo; data is in units of Wh/m2 and we are converting it to KWh/m2.\nThe resulting dataframe contains the monthly sum of \u0026ldquo;GHI\u0026rdquo; for the year 2016 in Seattle.\n2016-01-31 33.661 2016-02-29 49.141 2016-03-31 90.370 2016-04-30 154.304 2016-05-31 169.188 2016-06-30 198.978 2016-07-31 191.013 2016-08-31 180.028 2016-09-30 126.233 2016-10-31 61.287 2016-11-30 35.059 2016-12-31 45.311 Freq: M, Name: GHI, dtype: float64 We can now repeat the process for Boston and Austin to get the monthly sum of \u0026ldquo;GHI\u0026rdquo; in 2016, boston_ghi_monthly_sum and austin_ghi_monthly_sum (If you want to see the code for Boston and Austin, check out the jupyter notebook).\nLet\u0026rsquo;s put all the monthly GHI data into a single dataframe.\nimport pandas as pd import numpy as np index = [\u0026#34;Jan\u0026#34;, \u0026#34;Feb\u0026#34;, \u0026#34;Mar\u0026#34;, \u0026#34;Apr\u0026#34;, \u0026#34;May\u0026#34;, \u0026#34;Jun\u0026#34;, \u0026#34;Jul\u0026#34;, \u0026#34;Aug\u0026#34;, \u0026#34;Sep\u0026#34;, \u0026#34;Oct\u0026#34;, \u0026#34;Nov\u0026#34;, \u0026#34;Dec\u0026#34;] ghi_df = pd.DataFrame( np.array([ seattle_ghi_monthly_sum.values, boston_ghi_monthly_sum.values, austin_ghi_monthyl_sum.values ]).T, columns=[\u0026#34;Seattle\u0026#34;, \u0026#34;Boston\u0026#34;, \u0026#34;Austin\u0026#34;], index=index ) Finally, let\u0026rsquo;s get GHI data for Berlin. NSRDB doesn\u0026rsquo;t have data for Berlin but we can get it from PVGIS, a tool provided by the European Union science hub. After downloading the data, we can load it as a pandas dataframe.\nberlin_monthly_df = (pd.read_csv(\u0026#34;Monthlydata_52.516_13.377_SA_2016_2016.csv\u0026#34;, sep=\u0026#34;\\t\u0026#34;, skiprows=4, skipfooter=4) .dropna(axis=1) .rename(columns={\u0026#34;H(h)_m\u0026#34; : \u0026#34;monthly_ghi_kWh_m2\u0026#34;}) ) ghi_df[\u0026#34;Berlin\u0026#34;] = berlin_monthly_df[\u0026#34;monthly_ghi_kWh_m2\u0026#34;].values Seattle\tBoston\tAustin\tBerlin Jan\t33.661\t64.608\t111.509\t16.03 Feb\t49.141\t83.216\t135.596\t37.93 Mar\t90.370\t119.618\t153.963\t64.28 Apr\t154.304\t160.144\t162.074\t120.44 May\t169.188\t174.102\t166.599\t182.66 Jun\t198.978\t213.426\t211.531\t173.66 Jul\t191.013\t199.640\t229.077\t151.20 Aug\t180.028\t184.762\t187.451\t142.08 Sep\t126.233\t124.293\t165.196\t117.23 Oct\t61.287\t96.820\t152.188\t40.18 Nov\t35.059\t61.626\t93.345\t25.73 Dec\t45.311\t54.708\t71.597\t15.45 Let\u0026rsquo;s visualize the differences in the irradiance data.\nimport seaborn as sns ax = sns.barplot(data=ghi_df, ci=\u0026#34;sd\u0026#34;) ax.set_ylabel(\u0026#34;KWh/m$^{2}$ per month\u0026#34;) ax.set_title(\u0026#34;Global Horizontal Irradiance\u0026#34;) The barplot shows the average global horizontal irradiance per month (with errorbars representing the standard deviation) for the different cities in our dataframe.\nax = ghi_df.plot( kind=\u0026#34;line\u0026#34;, ylabel=\u0026#34;KWh per m$^{2}$\u0026#34;, title=\u0026#34;Total Monthly Global Horizontal Irradiance\u0026#34;, style=[\u0026#34;o-\u0026#34;, \u0026#34;o-\u0026#34;, \u0026#34;o-\u0026#34;, \u0026#34;o-\u0026#34;] ) The lineplot shows the monthly sum of global horizontal irradiance for the different cities in our dataframe.\n# Annual Global Horizontal Irradiance ghi_df.sum() # KWh/m2 Seattle 1334.573 Boston 1536.963 Austin 1840.126 Berlin 1086.870 dtype: float64 Seattle gets sunlight comparable to Boston but lower than Austin, monthly as well as annually. The fall and winter months receive less sunlight, which is not surprising.\nHowever, when we compare Seattle with Berlin, we see that Seattle gets higher solar irradiance thorughout the year. This is very promising for solar in Seattle (and Washington).\nIn 2020, Germany produced 51 TWh of electricity from solar despite getting less sun than Seattle! That\u0026rsquo;s 10.5% of Germany\u0026rsquo;s electricity generation.\nOf course, there are differences in policies and cost of solar; but looking at the solar resource availability, there is no reason why solar energy can\u0026rsquo;t be more successful in Seattle, Washington and the US in general.\nThanks for reading! You can find the notebook with the code here.\n","permalink":"https://sarthakjariwala.github.io/posts/sunny-in-seattle/","summary":"A comparative look at solar resource availability\nIs solar energy a viable resource for a city like Seattle? My friend recently asked me this question. I believe it\u0026rsquo;s a fair question to ask. Seattle isn\u0026rsquo;t known for its abundance of sunshine. As I write this post, it is a gloomy, cloudy and rainy day in Seattle. For those familiar with Seattle weather, this is not a surprise - fall and winter months are often cloudy and rainy.","title":"How Sunny is Seattle?"},{"content":" Add scalebars, visualize image distribution, correct outliers, and more.\nThis post introduces some of the functionalities in seaborn-image for descriptive, effective and attractive image visualization.\nSeaborn-image is an open source python visualization library for images built on top of matplotlib. It aims to provide a high level API to visualize image data similar to how seaborn provides high level API to visualize tabular data. As the name suggests, seaborn-image is heavily inspired by the seaborn library.\nInstallation 2-D Images Add Scalebar Correct Outliers Image Data Distribution Installation Let\u0026rsquo;s begin by installing seaborn-image\n$ pip install --upgrade seaborn-image and then importing seaborn-image as isns\nimport seaborn_image as isns # set context isns.set_context(\u0026#34;notebook\u0026#34;) # set global image settings isns.set_image(cmap=\u0026#34;deep\u0026#34;, origin=\u0026#34;lower\u0026#34;) # load sample dataset polymer = isns.load_image(\u0026#34;polymer\u0026#34;) All the functions in seaborn-image are available in a flat namespace.\nisns.set_context() helps us globally change the display contexts (similar to seaborn.set_context()).\nIn addition to the context, we also globally set properties for drawing our image using isns.set_image(). Later, we will also look at globally setting image scalebar properties using isns.set_scalebar().\nUnder the hood, these functions use matplotlib rcParams for customizing displays. You can refer to the docs for more details on settings in seaborn-image.\nLastly, we load a sample polymer dataset from seaborn-image.\n2-D Images Visualizing the image is as simple as calling the imgplot() function with the image data. imgplot() uses matplotlib imshow under the hood but provides easy access to a lot of customizations. We will take a look at a few of the customizations in this blog post.\nBy default, it adds a colorbar and turns off axis ticks. However, that is only beginning to scratch the surface!\nWe can get some basic descriptive statistics about our image data by setting describe=True.\nax = isns.imgplot( polymer, describe=True, # default is False ) No. of Obs. : 65536 Min. Value : -8.2457214 Max. Value : 43.714034999999996 Mean : 7.456410761947062 Variance : 92.02680396572863 Skewness : 0.47745180538933696 You can also use imshow, an alias for imgplot\nDraw a Scalebar Although we know some basic information about our image data, we still do not have any information about the physical size of the features in the image. We can draw a scalebar to rectify it.\nTo add a scalebar to the image we can specify the individul pixel size dx and physical units. Here, the individual pixel is 15 nanometers in physical size. So, we set dx=15 and units=\u0026quot;nm\u0026quot;.\nax = isns.imgplot( polymer, dx=15, # physical size of the pixel units=\u0026#34;nm\u0026#34;, # units cbar_label=\u0026#34;Height (nm)\u0026#34; # colorbar label to our image ) Note: We only specified the individual pixel size and units, and a scalebar of appropriate size was drawn.\nTip: You can change the scalebar properties such as scalebar location, label location, color, etc. globally using isns.set_scalebar()\nCorrect for Outliers Real data is never perfect. It is often riddled with outliers and these outliers affect the image display.\n# sample data with outliers pol_outliers = isns.load_image(\u0026#34;polymer outliers\u0026#34;) ax = isns.imgplot(pol_outliers, cbar_label=\u0026#34;Height (nm)\u0026#34;) The above example dataset has a single outlier pixel which is affecting the image display. We can correct for the outliers using the robust parameter in all seaborn-image functions.\nax = isns.imgplot( pol_outliers, robust=True, # set robust plotting perc=(0.5, 99.5), # set the percentile of the data to view cbar_label=\u0026#34;Height (nm)\u0026#34; ) Here, we are setting robust=True and plotting 0.5 to 99.5 percentile of the data (specified using the perc parameter). Doing so appropriately scales the colormap based on the robust percentile specified and also draws colorbar extensions without any additional code.\nNote: You can specify the vmin and vmax parameter to override the robust parameter. See imgplot documentation examples for more details\nImage Data Distribution One of the most important things in image visualization is knowing the distribution of the underlying image data. Here, we are using imghist() to plot a histogram along with the image.\nfig = isns.imghist(polymer, dx=15, units=\u0026#34;nm\u0026#34;, cbar_label=\u0026#34;Height (nm)\u0026#34;) Note that there are no new parameters required.\nUsing histogram along with an appropriate colormap provides additional information about the image data. For instance, from the histogram above, we can see that majority of the data has values less than 30 nm and there are very few values that are close to 40 nm - something that may not be obvious if we look at the image without the histogram.\nTip: You can change the number of bins using the bins parameter and the orientation of the colorbar and histogram using the orientation parameter. See imghist documentation examples for more details\nImportantly, generating the entire figure - with a histogram matching the colorbar levels, scalebar describing the physical size of the features in the image, colorbar label, hiding axis ticks, etc. - took only one line of code. In essence, this is what seaborn-image aims to provide - a high level API for attractive, descriptive and effective image visualization.\nLastly, this post has only introduced some of the high level API that seaborn-image provides for image visualization. For more details, you can check out the detailed documentation and tutorials and the project on GitHub.\nThanks for reading!\n","permalink":"https://sarthakjariwala.github.io/posts/introducing-seaborn-image/","summary":"Add scalebars, visualize image distribution, correct outliers, and more.\nThis post introduces some of the functionalities in seaborn-image for descriptive, effective and attractive image visualization.\nSeaborn-image is an open source python visualization library for images built on top of matplotlib. It aims to provide a high level API to visualize image data similar to how seaborn provides high level API to visualize tabular data. As the name suggests, seaborn-image is heavily inspired by the seaborn library.","title":"Attractive, Effective \u0026 Descriptive Image Visualization in Python"},{"content":"Multi-dimensional image data is, generally speaking, cumbersome to visualize.\nIn scientific imaging (or in most imaging areas), multi-dimensional images are very common. The additional dimension could be anything from the physical 3rd dimension (\u0026ldquo;Z axis\u0026rdquo;), where 2D images are taken at different depths; to the time dimension, where 2D images are taken at different time intervals; to different channels in scientific imaging instruments such as atomic force microscopes or in RGB images.\nWe will use seaborn-image, an open source image visualization library in Python based on matplotlib.\nIt is heavily inspired by the popular seaborn library for statistical visualization\nInstallation pip install -U seaborn-image You can find out more about the seaborn-image project on GitHub.\nLoad sample 3D data import seaborn_image as isns cells = isns.load_image(\u0026#34;cells\u0026#34;) cells.shape (256, 256, 60) Visualize We will use ImageGrid from seaborn_image to visualize the data. It will plot a series of images on a grid.\nTo begin, we will only plot a few selected slices using the slices keyword argument.\ng = isns.ImageGrid(cells, slices=[10, 20, 30, 40, 50]) By default, the slices are taken along the last axis. However, we can take them along another dimension using the axis keyword argument.\ng = isns.ImageGrid(cells, slices=[10, 20, 30, 40, 50], axis=0) We can also specify different start/stop points as well as step sizes to take using the start, stop and step parameters, respectively.\nIn the code below, we are starting with the 10th slice and going up to the 40th slice with steps of 3.\nThe slices and steps are taken over the last axis if not specified.\ng = isns.ImageGrid(cells, start=10, stop=40, step=3) We can also just plot all the images without any indexing or slicing.\ng = isns.ImageGrid(cells, cbar=False, height=1, col_wrap=10) Note - We altered the height of the individual images and the number of image columns.\nTransformations Finally, we can also apply transformations to the image and visualize it. Here, we will adjust the exposure using the adjust_gamma function from scikit-image.\nWe can achieve this by passing the function object to the map_func parameter. Additional parameters to the function object can be passed as keyword arguments.\nfrom skimage import exposure g = isns.ImageGrid( cells, map_func=exposure.adjust_gamma, # function to map gamma=0.5, # additional keyword for `adjust_gamma` cbar=False, height=1, col_wrap=10) ImageGrid returns a seaborn_image.ImageGrid object and is a figure-level function, i.e. it generates a new matplotlib figure. We can access the figure and all the individual axes using the fig and axes attributes, respectively. This means that for any customizations that are not directly available in seaborn-image (see documentation), we can drop down to matplotlib and use its powerful API.\nOverall, as we have seen throughout this post, seaborn-image allows us to be more productive by providing a high-level API for quick, effective and attractive image data visualization.\nYou can find out more about the seaborn-image project on GitHub.\nThanks for reading!\n","permalink":"https://sarthakjariwala.github.io/posts/multi-dimension-image-data/","summary":"Multi-dimensional image data is, generally speaking, cumbersome to visualize.\nIn scientific imaging (or in most imaging areas), multi-dimensional images are very common. The additional dimension could be anything from the physical 3rd dimension (\u0026ldquo;Z axis\u0026rdquo;), where 2D images are taken at different depths; to the time dimension, where 2D images are taken at different time intervals; to different channels in scientific imaging instruments such as atomic force microscopes or in RGB images.","title":"Effective Visualization of Multi-Dimension Image Data in Python"},{"content":"Sr. Software Engineer at Twelve. Before that I was a Research Scientist at Palo Alto Research Center (PARC)\nI work at the intersection of software and hardware interfaces, materials, and machine learning.\nI combine my expertise in these areas to solve scientific problems and commercial challenges.\nI have published 10+ peer-reviewed articles in leading materials and energy journals. and have extensive experience developing software tools and libraries. You can check out my open-source libraries and tools here.\nI have significant experience in expertly communicating complex information to stakeholders and technical \u0026amp; general audience, and in providing actionable insights from data collected and critically analyzed with scientific rigor.\nYou can connect with me on LinkedIn/Twitter or reach me via email (hi AT sarthakjariwala.com).\n","permalink":"https://sarthakjariwala.github.io/about/","summary":"Sr. Software Engineer at Twelve. Before that I was a Research Scientist at Palo Alto Research Center (PARC)\nI work at the intersection of software and hardware interfaces, materials, and machine learning.\nI combine my expertise in these areas to solve scientific problems and commercial challenges.\nI have published 10+ peer-reviewed articles in leading materials and energy journals. and have extensive experience developing software tools and libraries. You can check out my open-source libraries and tools here.","title":"About Me"},{"content":" Developed, packaged, and published a physics-informed deep learning model to automate the localization, classification, and visualization of defects in 2D materials.\nAdvances in scanning transmission electron microscopy (STEM) have allowed unprecedented insight into the elementary mechanisms behind the solid-state phase transformations and reactions.\nHowever, the ability to quickly acquire large, high-resolution datasets has created a challenge for rapid physics-based analysis of STEM images and movies.\nIn this project, I developed a software package, defectfinder, that allows the user to develop a convolutional neural network (CNN) based framework to automate the localization, classification and visualization of defects in 2D materials from dynamic STEM data.\ndefectfinder allows the user to localize and extract the defects frame by frame using fast-fourier transform (FFT), subtraction and lattice periodicity, and predict the defect type for all the localized defects. defectfinder also allows defect visualization by type and the interplay between the different defect types and time.\nLearn more about it here.\n","permalink":"https://sarthakjariwala.github.io/projects/automated-defect-discovery/","summary":"Developed, packaged, and published a physics-informed deep learning model to automate the localization, classification, and visualization of defects in 2D materials.\nAdvances in scanning transmission electron microscopy (STEM) have allowed unprecedented insight into the elementary mechanisms behind the solid-state phase transformations and reactions.\nHowever, the ability to quickly acquire large, high-resolution datasets has created a challenge for rapid physics-based analysis of STEM images and movies.\nIn this project, I developed a software package, defectfinder, that allows the user to develop a convolutional neural network (CNN) based framework to automate the localization, classification and visualization of defects in 2D materials from dynamic STEM data.","title":"Automated Defect Discovery Using Deep Learning"},{"content":" Elucidating local compositional and structural variations in high-performing solar cells using advanced analytics applied to novel characterization techniques.\nLearn more in the paper: Jariwala et al., ACS Energy Lett. 2022, 7, 1, 204–210.\n","permalink":"https://sarthakjariwala.github.io/projects/dma-heterogeneity/","summary":"Elucidating local compositional and structural variations in high-performing solar cells using advanced analytics applied to novel characterization techniques.\nLearn more in the paper: Jariwala et al., ACS Energy Lett. 2022, 7, 1, 204–210.","title":"Leveraging Analytics and Characterization to Investigate Heterogeneity"},{"content":"I create and maintain various open source software libraries and applications. Below is a list of some of the projects:\nseaborn-image High-level API for attractive and descriptive image visualization in Python.\nGitHub | Documentation | Introductory Post\nEZconda Create, Manage, Re-create conda environments \u0026amp; specifications with ease.\nGitHub | Documentation\nnrel-dev-api Developer friendly Python API for accessing National Renewable Energy Lab developer resources.\nGitHub | Documentation | Introductory Post\nprayog Optimization API for experimental science.\nGitHub\nPV Limit: Desktop and Web App A web and desktop application for scientists to calculate the maximum efficiency of a solar cell with various materials under different temperatures.\nWeb application | Desktop application\nGLabViz Explore and analyze outcoming data from various scientific hardware using an intuitive GUI.\nGitHub\nData Acquisition Intuitive platforms for data acquisition and control using Qt and Python for various scientific hardware/instruments.\nGitHub.\npyscaffold-nox Pyscaffold extension for adding a noxfile.\nGitHub\npyscaffold-interactive An interactive Python project template generator based on PyScaffold.\nThis project is archived.\nBZMAN BZMAN (business manager) - Designed to be minimal and for small business needs. Written completely in Python.\nGitHub\nI also contribute to open-source libraries.\nmatplotlib-scalebar Provides a new artist for matplotlib to display a scale bar, aka micron bar.\nGitHub\nvispy High-performance interactive 2D/3D data visualization library.\nGitHub\nScopefoundry A Python platform for controlling custom laboratory experiments and visualizing scientific data\nGitHub\n","permalink":"https://sarthakjariwala.github.io/open-source-software/","summary":"I create and maintain various open source software libraries and applications. Below is a list of some of the projects:\nseaborn-image High-level API for attractive and descriptive image visualization in Python.\nGitHub | Documentation | Introductory Post\nEZconda Create, Manage, Re-create conda environments \u0026amp; specifications with ease.\nGitHub | Documentation\nnrel-dev-api Developer friendly Python API for accessing National Renewable Energy Lab developer resources.\nGitHub | Documentation | Introductory Post\nprayog Optimization API for experimental science.","title":"Open Source Software"},{"content":" Used image processing and machine learning for predictive analysis of self-assembled peptides on various substrates as imaged using Atomic Force Microscope.\nDeveloped software framework using image processing and machine learning to identify different textural components and their segmentation in Atomic Force Microscope (AFM) images of self-assembled peptide structures.\nFrom AFM image data, the software helps end users:\nApproximate the effect of natural tip drift which is ubiquitous in AFM characterization Correct for noise Detect different textures based on how ordered or disordered the self-assembly is Calculate: Percent coverage of each texture Overall percent coverage of the self assembled peptides Ordered to disordered ratio (Degree of disorder) This helps evaluate the self assembly properties of the peptides on the substrates for the processing conditions.\nLearn more about the project here\n","permalink":"https://sarthakjariwala.github.io/projects/predictive-peptides/","summary":"Used image processing and machine learning for predictive analysis of self-assembled peptides on various substrates as imaged using Atomic Force Microscope.\nDeveloped software framework using image processing and machine learning to identify different textural components and their segmentation in Atomic Force Microscope (AFM) images of self-assembled peptide structures.\nFrom AFM image data, the software helps end users:\nApproximate the effect of natural tip drift which is ubiquitous in AFM characterization Correct for noise Detect different textures based on how ordered or disordered the self-assembly is Calculate: Percent coverage of each texture Overall percent coverage of the self assembled peptides Ordered to disordered ratio (Degree of disorder) This helps evaluate the self assembly properties of the peptides on the substrates for the processing conditions.","title":"Predicting Peptide Interface Parameters"},{"content":"As a senior technical member of Global Renewable Infrastructure Development (GRID) at the University of Washington :\nPerformed techno-economic analysis using SAM (System Advisor Model) and PySAM for designing a solar-powered school \u0026amp; community library in rural Ghana.\nDeveloped remote data tracking system for monitoring the health and performance of installed solar modules and microgrids.\n","permalink":"https://sarthakjariwala.github.io/projects/solar-techno-economic-analysis/","summary":"As a senior technical member of Global Renewable Infrastructure Development (GRID) at the University of Washington :\nPerformed techno-economic analysis using SAM (System Advisor Model) and PySAM for designing a solar-powered school \u0026amp; community library in rural Ghana.\nDeveloped remote data tracking system for monitoring the health and performance of installed solar modules and microgrids.","title":"Solar Techno Economic Analysis"},{"content":" Elucidate structure-property relationships in next-generation solar cell technology.\nUsed statistical methods in combination with expertise in image \u0026amp; data analysis and domain knowledge to elucidate structure-property relationships in next-generation solar cell technology.\nLearn more about the project in the news coverage and paper.\n","permalink":"https://sarthakjariwala.github.io/projects/structure-property-relationships/","summary":"Elucidate structure-property relationships in next-generation solar cell technology.\nUsed statistical methods in combination with expertise in image \u0026amp; data analysis and domain knowledge to elucidate structure-property relationships in next-generation solar cell technology.\nLearn more about the project in the news coverage and paper.","title":"Structure Property Relationships in Next-Gen Solar Materials"}]